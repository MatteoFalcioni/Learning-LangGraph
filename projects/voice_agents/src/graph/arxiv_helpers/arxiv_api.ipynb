{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "747c592a",
   "metadata": {},
   "source": [
    "# ArXiv API "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b8adba",
   "metadata": {},
   "source": [
    "Testing the arxiv api functioning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22c92c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import arxiv\n",
    "from typing import Literal\n",
    "\n",
    "def search_arxiv(\n",
    "    query: str, \n",
    "    max_results: int = 10, \n",
    "    sort_criterion : Literal['relevance', 'last_submitted'] = 'relevance'\n",
    ")-> str | list[dict]:\n",
    "    \"\"\"\n",
    "    Searches arXiv for the top N articles based on a query.\n",
    "    Returns a list of dictionaries containing article ID, title, summary, and authors.\n",
    "    \n",
    "    Args:\n",
    "        query (str): The search query (e.g., \"AI agents\", \"quantum computing\").\n",
    "        max_results (int): The maximum number of results to return. Default is 10.\n",
    "        sort_criterion (Literal['relevance', 'last_submitted']): The criterion to sort the results by. \n",
    "            Default is 'relevance': this sorts by relevance to the query.\n",
    "            'last_submitted' sorts by the date the article was submitted to the arXiv.\n",
    "    \"\"\"\n",
    "    client = arxiv.Client()\n",
    "\n",
    "    if sort_criterion == 'relevance':\n",
    "        sort_by = arxiv.SortCriterion.Relevance\n",
    "    elif sort_criterion == 'last_submitted':\n",
    "        sort_by = arxiv.SortCriterion.SubmittedDate\n",
    "    \n",
    "    search = arxiv.Search(\n",
    "        query=query,\n",
    "        max_results=max_results,\n",
    "        sort_by=sort_by\n",
    "    )\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    # client.results() is a generator\n",
    "    for result in client.results(search):\n",
    "        results.append({\n",
    "            # entry_id is a URL like 'http://arxiv.org/abs/2310.12345'\n",
    "            # We split to get just the ID '2310.12345'\n",
    "            \"id\": result.entry_id.split('/')[-1],\n",
    "            \"title\": result.title,\n",
    "            \"published\": result.published.strftime(\"%Y-%m-%d\"),\n",
    "            \"authors\": [author.name for author in result.authors],\n",
    "            \"summary\": result.summary.replace(\"\\n\", \" \") # Clean up newlines in abstract\n",
    "        })\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d7887a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '2501.02842v1', 'title': 'Foundations of GenIR', 'published': '2025-01-06', 'authors': ['Qingyao Ai', 'Jingtao Zhan', 'Yiqun Liu'], 'summary': 'The chapter discusses the foundational impact of modern generative AI models on information access (IA) systems. In contrast to traditional AI, the large-scale training and superior data modeling of generative AI models enable them to produce high-quality, human-like responses, which brings brand new opportunities for the development of IA paradigms. In this chapter, we identify and introduce two of them in details, i.e., information generation and information synthesis. Information generation allows AI to create tailored content addressing user needs directly, enhancing user experience with immediate, relevant outputs. Information synthesis leverages the ability of generative AI to integrate and reorganize existing information, providing grounded responses and mitigating issues like model hallucination, which is particularly valuable in scenarios requiring precision and external knowledge. This chapter delves into the foundational aspects of generative models, including architecture, scaling, and training, and discusses their applications in multi-modal scenarios. Additionally, it examines the retrieval-augmented generation paradigm and other methods for corpus modeling and understanding, demonstrating how generative AI can enhance information access systems. It also summarizes potential challenges and fruitful directions for future studies.'}\n",
      "\n",
      "{'id': '2510.01751v1', 'title': 'A cybersecurity AI agent selection and decision support framework', 'published': '2025-10-02', 'authors': ['Masike Malatji'], 'summary': \"This paper presents a novel, structured decision support framework that systematically aligns diverse artificial intelligence (AI) agent architectures, reactive, cognitive, hybrid, and learning, with the comprehensive National Institute of Standards and Technology (NIST) Cybersecurity Framework (CSF) 2.0. By integrating agent theory with industry guidelines, this framework provides a transparent and stepwise methodology for selecting and deploying AI solutions to address contemporary cyber threats. Employing a granular decomposition of NIST CSF 2.0 functions into specific tasks, the study links essential AI agent properties such as autonomy, adaptive learning, and real-time responsiveness to each subcategory's security requirements. In addition, it outlines graduated levels of autonomy (assisted, augmented, and fully autonomous) to accommodate organisations at varying stages of cybersecurity maturity. This holistic approach transcends isolated AI applications, providing a unified detection, incident response, and governance strategy. Through conceptual validation, the framework demonstrates how tailored AI agent deployments can align with real-world constraints and risk profiles, enhancing situational awareness, accelerating response times, and fortifying long-term resilience via adaptive risk management. Ultimately, this research bridges the gap between theoretical AI constructs and operational cybersecurity demands, establishing a foundation for robust, empirically validated multi-agent systems that adhere to industry standards.\"}\n",
      "\n",
      "{'id': '2510.09567v1', 'title': 'Safe, Untrusted, \"Proof-Carrying\" AI Agents: toward the agentic lakehouse', 'published': '2025-10-10', 'authors': ['Jacopo Tagliabue', 'Ciro Greco'], 'summary': 'Data lakehouses run sensitive workloads, where AI-driven automation raises concerns about trust, correctness, and governance. We argue that API-first, programmable lakehouses provide the right abstractions for safe-by-design, agentic workflows. Using Bauplan as a case study, we show how data branching and declarative environments extend naturally to agents, enabling reproducibility and observability while reducing the attack surface. We present a proof-of-concept in which agents repair data pipelines using correctness checks inspired by proof-carrying code. Our prototype demonstrates that untrusted AI agents can operate safely on production data and outlines a path toward a fully agentic lakehouse.'}\n",
      "\n",
      "{'id': '2509.00961v1', 'title': 'Ultra Strong Machine Learning: Teaching Humans Active Learning Strategies via Automated AI Explanations', 'published': '2025-08-31', 'authors': ['Lun Ai', 'Johannes Langer', 'Ute Schmid', 'Stephen Muggleton'], 'summary': 'Ultra Strong Machine Learning (USML) refers to symbolic learning systems that not only improve their own performance but can also teach their acquired knowledge to quantifiably improve human performance. In this work, we present LENS (Logic Programming Explanation via Neural Summarisation), a neuro-symbolic method that combines symbolic program synthesis with large language models (LLMs) to automate the explanation of machine-learned logic programs in natural language. LENS addresses a key limitation of prior USML approaches by replacing hand-crafted explanation templates with scalable automated generation. Through systematic evaluation using multiple LLM judges and human validation, we demonstrate that LENS generates superior explanations compared to direct LLM prompting and hand-crafted templates. To investigate whether LENS can teach transferable active learning strategies, we carried out a human learning experiment across three related domains. Our results show no significant human performance improvements, suggesting that comprehensive LLM responses may overwhelm users for simpler problems rather than providing learning support. Our work provides a solid foundation for building effective USML systems to support human learning. The source code is available on: https://github.com/lun-ai/LENS.git.'}\n",
      "\n",
      "{'id': '2112.01298v2', 'title': 'Meaningful human control: actionable properties for AI system development', 'published': '2021-11-25', 'authors': ['Luciano Cavalcante Siebert', 'Maria Luce Lupetti', 'Evgeni Aizenberg', 'Niek Beckers', 'Arkady Zgonnikov', 'Herman Veluwenkamp', 'David Abbink', 'Elisa Giaccardi', 'Geert-Jan Houben', 'Catholijn M. Jonker', 'Jeroen van den Hoven', 'Deborah Forster', 'Reginald L. Lagendijk'], 'summary': \"How can humans remain in control of artificial intelligence (AI)-based systems designed to perform tasks autonomously? Such systems are increasingly ubiquitous, creating benefits - but also undesirable situations where moral responsibility for their actions cannot be properly attributed to any particular person or group. The concept of meaningful human control has been proposed to address responsibility gaps and mitigate them by establishing conditions that enable a proper attribution of responsibility for humans; however, clear requirements for researchers, designers, and engineers are yet inexistent, making the development of AI-based systems that remain under meaningful human control challenging. In this paper, we address the gap between philosophical theory and engineering practice by identifying, through an iterative process of abductive thinking, four actionable properties for AI-based systems under meaningful human control, which we discuss making use of two applications scenarios: automated vehicles and AI-based hiring. First, a system in which humans and AI algorithms interact should have an explicitly defined domain of morally loaded situations within which the system ought to operate. Second, humans and AI agents within the system should have appropriate and mutually compatible representations. Third, responsibility attributed to a human should be commensurate with that human's ability and authority to control the system. Fourth, there should be explicit links between the actions of the AI agents and actions of humans who are aware of their moral responsibility. We argue that these four properties will support practically-minded professionals to take concrete steps toward designing and engineering for AI systems that facilitate meaningful human control.\"}\n",
      "\n",
      "{'id': '2508.08544v1', 'title': 'AI Agents and the Law', 'published': '2025-08-12', 'authors': ['Mark O. Riedl', 'Deven R. Desai'], 'summary': 'As AI becomes more \"agentic,\" it faces technical and socio-legal issues it must address if it is to fulfill its promise of increased economic productivity and efficiency. This paper uses technical and legal perspectives to explain how things change when AI systems start being able to directly execute tasks on behalf of a user. We show how technical conceptions of agents track some, but not all, socio-legal conceptions of agency. That is, both computer science and the law recognize the problems of under-specification for an agent, and both disciplines have robust conceptions of how to address ensuring an agent does what the programmer, or in the law, the principal desires and no more. However, to date, computer science has under-theorized issues related to questions of loyalty and to third parties that interact with an agent, both of which are central parts of the law of agency. First, we examine the correlations between implied authority in agency law and the principle of value-alignment in AI, wherein AI systems must operate under imperfect objective specification. Second, we reveal gaps in the current computer science view of agents pertaining to the legal concepts of disclosure and loyalty, and how failure to account for them can result in unintended effects in AI ecommerce agents. In surfacing these gaps, we show a path forward for responsible AI agent development and deployment.'}\n",
      "\n",
      "{'id': '2503.15552v2', 'title': 'Personalized Attacks of Social Engineering in Multi-turn Conversations: LLM Agents for Simulation and Detection', 'published': '2025-03-18', 'authors': ['Tharindu Kumarage', 'Cameron Johnson', 'Jadie Adams', 'Lin Ai', 'Matthias Kirchner', 'Anthony Hoogs', 'Joshua Garland', 'Julia Hirschberg', 'Arslan Basharat', 'Huan Liu'], 'summary': \"The rapid advancement of conversational agents, particularly chatbots powered by Large Language Models (LLMs), poses a significant risk of social engineering (SE) attacks on social media platforms. SE detection in multi-turn, chat-based interactions is considerably more complex than single-instance detection due to the dynamic nature of these conversations. A critical factor in mitigating this threat is understanding the SE attack mechanisms through which SE attacks operate, specifically how attackers exploit vulnerabilities and how victims' personality traits contribute to their susceptibility. In this work, we propose an LLM-agentic framework, SE-VSim, to simulate SE attack mechanisms by generating multi-turn conversations. We model victim agents with varying personality traits to assess how psychological profiles influence susceptibility to manipulation. Using a dataset of over 1000 simulated conversations, we examine attack scenarios in which adversaries, posing as recruiters, funding agencies, and journalists, attempt to extract sensitive information. Based on this analysis, we present a proof of concept, SE-OmniGuard, to offer personalized protection to users by leveraging prior knowledge of the victims personality, evaluating attack strategies, and monitoring information exchanges in conversations to identify potential SE attempts.\"}\n",
      "\n",
      "{'id': '2308.12400v1', 'title': 'Towards The Ultimate Brain: Exploring Scientific Discovery with ChatGPT AI', 'published': '2023-07-08', 'authors': ['Gerardo Adesso'], 'summary': \"This paper presents a novel approach to scientific discovery using an artificial intelligence (AI) environment known as ChatGPT, developed by OpenAI. This is the first paper entirely generated with outputs from ChatGPT. We demonstrate how ChatGPT can be instructed through a gamification environment to define and benchmark hypothetical physical theories. Through this environment, ChatGPT successfully simulates the creation of a new improved model, called GPT$^4$, which combines the concepts of GPT in AI (generative pretrained transformer) and GPT in physics (generalized probabilistic theory). We show that GPT$^4$ can use its built-in mathematical and statistical capabilities to simulate and analyze physical laws and phenomena. As a demonstration of its language capabilities, GPT$^4$ also generates a limerick about itself. Overall, our results demonstrate the promising potential for human-AI collaboration in scientific discovery, as well as the importance of designing systems that effectively integrate AI's capabilities with human intelligence.\"}\n",
      "\n",
      "{'id': '2408.00025v3', 'title': 'Need of AI in Modern Education: in the Eyes of Explainable AI (xAI)', 'published': '2024-07-31', 'authors': ['Supriya Manna', 'Niladri Sett'], 'summary': \"Modern Education is not \\\\textit{Modern} without AI. However, AI's complex nature makes understanding and fixing problems challenging. Research worldwide shows that a parent's income greatly influences a child's education. This led us to explore how AI, especially complex models, makes important decisions using Explainable AI tools. Our research uncovered many complexities linked to parental income and offered reasonable explanations for these decisions. However, we also found biases in AI that go against what we want from AI in education: clear transparency and equal access for everyone. These biases can impact families and children's schooling, highlighting the need for better AI solutions that offer fair opportunities to all. This chapter tries to shed light on the complex ways AI operates, especially concerning biases. These are the foundational steps towards better educational policies, which include using AI in ways that are more reliable, accountable, and beneficial for everyone involved.\"}\n",
      "\n",
      "{'id': '2401.15284v6', 'title': 'Beyond principlism: Practical strategies for ethical AI use in research practices', 'published': '2024-01-27', 'authors': ['Zhicheng Lin'], 'summary': 'The rapid adoption of generative artificial intelligence (AI) in scientific research, particularly large language models (LLMs), has outpaced the development of ethical guidelines, leading to a \"Triple-Too\" problem: too many high-level ethical initiatives, too abstract principles lacking contextual and practical relevance, and too much focus on restrictions and risks over benefits and utilities. Existing approaches--principlism (reliance on abstract ethical principles), formalism (rigid application of rules), and technological solutionism (overemphasis on technological fixes)--offer little practical guidance for addressing ethical challenges of AI in scientific research practices. To bridge the gap between abstract principles and day-to-day research practices, a user-centered, realism-inspired approach is proposed here. It outlines five specific goals for ethical AI use: 1) understanding model training and output, including bias mitigation strategies; 2) respecting privacy, confidentiality, and copyright; 3) avoiding plagiarism and policy violations; 4) applying AI beneficially compared to alternatives; and 5) using AI transparently and reproducibly. Each goal is accompanied by actionable strategies and realistic cases of misuse and corrective measures. I argue that ethical AI application requires evaluating its utility against existing alternatives rather than isolated performance metrics. Additionally, I propose documentation guidelines to enhance transparency and reproducibility in AI-assisted research. Moving forward, we need targeted professional development, training programs, and balanced enforcement mechanisms to promote responsible AI use while fostering innovation. By refining these ethical guidelines and adapting them to emerging AI capabilities, we can accelerate scientific progress without compromising research integrity.'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test it out:\n",
    "\n",
    "result = search_arxiv(query=\"AI agents\")\n",
    "\n",
    "for entry in result:\n",
    "    print(entry)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce6b522",
   "metadata": {},
   "source": [
    "Can we read the article without downloading it to the local file system? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4e74769d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import arxiv\n",
    "import requests\n",
    "import pymupdf  \n",
    "from langchain_core.tools import tool\n",
    "\n",
    "def read_arxiv_in_memory(paper_id: str, start_page: int = 1, end_page: int = 3):\n",
    "    \"\"\"\n",
    "    Downloads an arXiv paper and returns text from specific pages.\n",
    "    Use this to read sections without loading the entire document.\n",
    "    \n",
    "    Args:\n",
    "        paper_id (str): The arXiv ID (e.g., \"2103.00020\").\n",
    "        start_page (int): The first page to read (1-based index). Default is 1.\n",
    "        end_page (int): The last page to read (1-based index). Default is 3.\n",
    "    \"\"\"\n",
    "    # 1. Fetch PDF URL\n",
    "    client = arxiv.Client()\n",
    "    try:\n",
    "        paper = next(client.results(arxiv.Search(id_list=[paper_id])))\n",
    "        pdf_url = paper.pdf_url\n",
    "    except StopIteration:\n",
    "        return f\"Error: Paper {paper_id} not found.\"\n",
    "\n",
    "    # 2. Download to RAM\n",
    "    try:\n",
    "        response = requests.get(pdf_url)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        # 3. Open PDF stream\n",
    "        with pymupdf.open(stream=response.content, filetype=\"pdf\") as doc:\n",
    "            num_pages = len(doc)\n",
    "            \n",
    "            # Validate page numbers\n",
    "            if start_page < 1: start_page = 1\n",
    "            if end_page > num_pages: end_page = num_pages\n",
    "            \n",
    "            # Convert to 0-based index for PyMuPDF\n",
    "            # We iterate only the requested range\n",
    "            text_content = []\n",
    "            for i in range(start_page - 1, end_page):\n",
    "                page_text = doc[i].get_text()\n",
    "                text_content.append(f\"--- Page {i+1} ---\\n{page_text}\")\n",
    "            \n",
    "            return \"\\n\".join(text_content)\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Error reading paper: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "832c1462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Page 1 ---\n",
      "Foundations of GenIR\n",
      "Qingyao Ai1†, Jingtao Zhan1†, Yiqun Liu1\n",
      "1Dept. of Computer Science and Technology, Tsinghua University,\n",
      "Beijing, China.\n",
      "Contributing authors: aiqy@tsinghua.edu.cn;\n",
      "zhanjt20@mails.tsinghua.edu.cn; yiqunliu@tsinghua.edu.cn;\n",
      "†These authors contributed equally to this work.\n",
      "Abstract\n",
      "The chapter discusses the foundational impact of modern generative AI models\n",
      "on information access (IA) systems. In contrast to traditional AI, the large-scale\n",
      "training and superior data modeling of generative AI models enable them to pro-\n",
      "duce high-quality, human-like responses, which brings brand new opportunities\n",
      "for the development of IA paradigms. In this chapter, we identify and introduce\n",
      "two of them in details, i.e., information generation and information synthesis.\n",
      "Information generation allows AI to create tailored content addressing user needs\n",
      "directly, enhancing user experience with immediate, relevant outputs. Information\n",
      "synthesis leverages the ability of generative AI to integrate and reorganize exist-\n",
      "ing information, providing grounded responses and mitigating issues like model\n",
      "hallucination, which is particularly valuable in scenarios requiring precision and\n",
      "external knowledge. This chapter delves into the foundational aspects of gener-\n",
      "ative models, including architecture, scaling, and training, and discusses their\n",
      "applications in multi-modal scenarios. Additionally, it examines the retrieval-\n",
      "augmented generation paradigm and other methods for corpus modeling and\n",
      "understanding, demonstrating how generative AI can enhance information access\n",
      "systems. It also summarizes potential challenges and fruitful directions for future\n",
      "studies.\n",
      "The primary distinction between modern generative models and traditional AI tech-\n",
      "niques lies in their capability to generate complicated and high-quality output based\n",
      "on human instructions. As shown by many studies [1–3], modern generative AI models\n",
      "possess remarkable abilities to generate responses that closely mimic human inter-\n",
      "action. General speaking, such impressive performance comes from their large-scale\n",
      "1\n",
      "arXiv:2501.02842v1  [cs.IR]  6 Jan 2025\n",
      "\n",
      "--- Page 2 ---\n",
      "training collections and their advanced data modeling algorithms. Their superior data\n",
      "understanding ability can benefit almost every components of existing information\n",
      "access systems, from document encoding and index construction, to query process-\n",
      "ing and relevance analysis, etc. However, when talking about new opportunities or\n",
      "paradigms that are uniquely brought by the generative AI to information access, they\n",
      "can be broadly categorized in two directions. The first one is to create content that\n",
      "directly addresses user’s information needs. By understanding and taking user queries\n",
      "as input instructions, generative AI models are able to generate specific answers or\n",
      "products tailored to the individual’s request. This direct approach to information gen-\n",
      "eration can significantly enhance user experience by providing immediate and relevant\n",
      "responses. The second direction is to leverage the advanced instruction-following capa-\n",
      "bilities of generative AI models to synthesize and recombine existing information in\n",
      "innovative ways. Generative AI such as large language models (LLMs) can take exist-\n",
      "ing data and transform it into new, coherent pieces of information that may not have\n",
      "been explicitly outlined before. This ability to reinterpret and organize information\n",
      "opens up new possibilities for retrieval system design and applications. Therefore, in\n",
      "this chapter, we discuss how generative AI models could help information access from\n",
      "two perspectives, namely information generation and information synthesis.\n",
      "1 Information Generation\n",
      "Information need is diverse and typically long-tail. Traditional information retrieval\n",
      "systems, such as search engines and recommendation platforms, are designed to present\n",
      "information that already exists. However, these systems often fall short when it comes\n",
      "to fulfilling the less common information needs. This is particularly evident in scenarios\n",
      "requiring creative creation, where users seek not just information but inspiration and\n",
      "novel ideas. The limitations of traditional information systems in addressing these\n",
      "unique demands have paved the way for the emergence of generative models, which\n",
      "hold the promise of creating new information that aligns closely with the long-tail\n",
      "information needs.\n",
      "In recent years, generative models have made significant developments. For\n",
      "instance, ChatGPT can respond to user questions, Bing enhances its responses\n",
      "with retrieval-augmented generation, and Midjourney generate images based on user\n",
      "prompts, and recommendation systems generate personal contents for different users.\n",
      "The development is mainly driven by the capable model architectures, computational\n",
      "resources, and the large-scale internet data. These elements have facilitated the per-\n",
      "formance of generative models to new heights. With the continuous efforts on scaling\n",
      "up these elements, the model performance is still rapidly improving. Nowadays, gener-\n",
      "ative models have gradually been integrated into various workflows and everyday life\n",
      "activities.\n",
      "In this section, we present the foundation of generative models. This section is\n",
      "organized as follows. Section 1.1 shows the efforts on designing the model architectures\n",
      "for large language models. Section 1.2 discusses how scaling facilitates the development\n",
      "of generative models and its potential future. Section 1.3 presents the different training\n",
      "stages of large language models. Finally, Section 1.4 introduces how large language\n",
      "models are used in multi-modal scenarios.\n",
      "2\n",
      "\n",
      "--- Page 3 ---\n",
      "1.1 Model Architecture\n",
      "In different generation scenarios like ChatGPT or SoRA, Transformer [4] has emerged\n",
      "as the predominant model structure. It starts with an embedding layer, followed by\n",
      "multiple neural layers. Within each layer, an attention mechanism models the interac-\n",
      "tions between words, creating contextualized embeddings. The final decision on word\n",
      "generation probabilities is derived by comparing the output embedding with the vocab-\n",
      "ulary embeddings. We illustrate the model architecture in Figure 1. Unlike traditional\n",
      "Recurrent Neural Networks [5], Transformers are capable of modeling long-distance\n",
      "interactions between words directly, which provides a more powerful representational\n",
      "capability. Numerous enhancements to the Transformer architecture have been pro-\n",
      "posed. In the following, we will explore various modifications to each component of the\n",
      "Transformer, highlighting the advancements that have further improved its efficacy\n",
      "and efficiency.\n",
      "Transformer\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "Output\n",
      "Tokens\n",
      "Positions\n",
      "Hidden \n",
      "States\n",
      "Attention\n",
      "Feed \n",
      "Forward\n",
      "Transformer Layer\n",
      "Fig. 1 Transformer architecture: the overview on the left and the illustration of one layer on the\n",
      "right [4].\n",
      "1.1.1 Word Embedding\n",
      "Word embedding module is at the bottom of the Transformer architecture. Initially, a\n",
      "tokenizer breaks down a sentence into tokens, which the Word embedding module then\n",
      "maps into embeddings. These are combined with position embeddings and fed into\n",
      "subsequent neural layers. Recent research on large-scale language models has identified\n",
      "word embeddings as one of the main sources to training instability [6]. Particularly\n",
      "in the early stages of training, the gradients of word embeddings are often orders of\n",
      "magnitude larger than those of other parameters. To address this issue, Le Scao et al.\n",
      "[7] introduced a layer normalization immediately after the word embedding layer,\n",
      "stabilizing the distribution effectively. Besides, Zeng et al. [6] opted to scale down the\n",
      "gradients of the word embeddings by an order of magnitude to prevent substantial\n",
      "updates. Both approaches have been proven effective in stabilizing the training of\n",
      "language models at the 100 billion parameter scale. Yet, whether they are still effective\n",
      "for larger models remains to be investigated.\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "text = read_arxiv_in_memory(result[0]['id'])\n",
    "lines = text.splitlines()\n",
    "for line in lines:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7937975",
   "metadata": {},
   "source": [
    "Now let's download the articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "44f2a295",
   "metadata": {},
   "outputs": [],
   "source": [
    "import arxiv\n",
    "import os\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "def download_arxiv_pdf(paper_id: str, save_dir: str = \"./downloads\"):\n",
    "    \"\"\"\n",
    "    Downloads the PDF of an arXiv paper given its ID.\n",
    "    \n",
    "    Args:\n",
    "        paper_id (str): The arXiv ID (e.g., \"2103.00020\").\n",
    "        save_dir (str): The directory to save the PDF in. Defaults to \"./downloads\".\n",
    "    \n",
    "    Returns:\n",
    "        str: The file path of the downloaded PDF.\n",
    "    \"\"\"\n",
    "    # Ensure directory exists\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    client = arxiv.Client()\n",
    "    \n",
    "    # We must \"search\" by ID to get the paper object\n",
    "    search = arxiv.Search(id_list=[paper_id])\n",
    "    \n",
    "    try:\n",
    "        paper = next(client.results(search))\n",
    "        \n",
    "        # Create a safe filename using the ID and a sanitized title\n",
    "        # e.g., \"2103.00020_Attention_Is_All_You_Need.pdf\"\n",
    "        safe_title = \"\".join(c for c in paper.title if c.isalnum() or c in (' ', '_', '-')).rstrip()\n",
    "        safe_title = safe_title.replace(\" \", \"_\")\n",
    "        filename = f\"{paper_id}_{safe_title}.pdf\"\n",
    "        \n",
    "        # Download\n",
    "        path = paper.download_pdf(dirpath=save_dir, filename=filename)\n",
    "        return f\"Successfully downloaded file to: {path}\"\n",
    "        \n",
    "    except StopIteration:\n",
    "        return f\"Error: Paper with ID {paper_id} not found.\"\n",
    "    except Exception as e:\n",
    "        return f\"Error downloading paper: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "06cb8841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2201.00978v1\n",
      "2106.02277v1\n",
      "2104.11502v1\n",
      "2208.03987v4\n",
      "2404.05657v1\n",
      "2107.03844v3\n",
      "2303.00957v1\n",
      "1901.02860v3\n",
      "2405.09508v2\n",
      "2302.14017v1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Successfully downloaded file to: ./test_downloads/2201.00978v1_PyramidTNT_Improved_Transformer-in-Transformer_Baselines_with_Pyramid_Architecture.pdf'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = search_arxiv(query=\"Transformer models\")\n",
    "\n",
    "for entry in result:\n",
    "    print(entry['id'])\n",
    "\n",
    "# Download the PDF\n",
    "download_arxiv_pdf(paper_id=result[0]['id'], save_dir=\"./test_downloads\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fa9ebdc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2106.02277v1_Glance-and-Gaze_Vision_Transformer.pdf', '2201.00978v1_PyramidTNT_Improved_Transformer-in-Transformer_Baselines_with_Pyramid_Architecture.pdf']\n"
     ]
    }
   ],
   "source": [
    "# list files in the downloads folder\n",
    "import os\n",
    "print(os.listdir(\"./test_downloads\"))    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
