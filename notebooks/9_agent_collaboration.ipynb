{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "426521f3",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/MatteoFalcioni/Learning-LangGraph/blob/main/notebooks/8_agent_collaboration.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0548b11f",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c3ee44",
   "metadata": {},
   "source": [
    "#### Install requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94e294f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q -U -r https://raw.githubusercontent.com/MatteoFalcioni/Learning-LangGraph/main/requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07cf0953",
   "metadata": {},
   "source": [
    "#### local (notebooks or files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3353e856",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()  # load api keys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a56ebd",
   "metadata": {},
   "source": [
    "#### Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8b85dd7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgoogle\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcolab\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m userdata\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m      4\u001b[39m REQUIRED_KEYS = [\n\u001b[32m      5\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mOPENAI_API_KEY\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m      6\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mLANGSMITH_TRACING\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m      9\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mLANGSMITH_PROJECT\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     10\u001b[39m ]\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "from google.colab import userdata\n",
    "import os\n",
    "\n",
    "REQUIRED_KEYS = [\n",
    "    'OPENAI_API_KEY',\n",
    "    'LANGSMITH_TRACING',\n",
    "    'LANGSMITH_ENDPOINT',\n",
    "    'LANGSMITH_API_KEY',\n",
    "    'LANGSMITH_PROJECT'\n",
    "]\n",
    "\n",
    "def _set_colab_keys(key : str):\n",
    "    # Retrieve the secret value using its key/name\n",
    "    secret_value = userdata.get(key)\n",
    "    # set it as a standard OS environment variable\n",
    "    os.environ[key] = secret_value\n",
    "\n",
    "for key in REQUIRED_KEYS:\n",
    "    _set_colab_keys(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9daf9842",
   "metadata": {},
   "source": [
    "### OpenRouter \n",
    "\n",
    "OpenRouter is a router that allows you to access many providers in a single API. Really useful to compare models and test new ones. \n",
    "\n",
    "We will use Qwen coder and Claude Haiku 4.5 later on. If you do not want to get an OpenRouter key, feel free to swap these models with OpenAI models as we always did until now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ae5ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "_set_colab_keys('OPENROUTER_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6afdd925",
   "metadata": {},
   "source": [
    "# Agent Collaboration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316d5a11",
   "metadata": {},
   "source": [
    "A single agent can usually operate effectively using a handful of tools within a single domain, but even using powerful models, it can be less effective at using many tools.\n",
    "\n",
    "One way to approach complicated tasks is through a \"divide-and-conquer\" approach: create a specialized agent for each task or domain and route tasks to the correct \"expert\". This is an example of a multi-agent network architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a0b2b6",
   "metadata": {},
   "source": [
    "Specifically,  in this example we will create a graph composed of two agents: \n",
    "\n",
    "- the **coder** agent writes code;\n",
    "- the **reviewer** reviews the code written by the coder, and either accepts (end workflow) it or rejects it (routes back to coder) with corrections. \n",
    "\n",
    "The graph we'll build looks like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d682922",
   "metadata": {},
   "source": [
    "<center>\n",
    "  <img src=\"images/SKETCH.png\" width=\"600\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c97ca59",
   "metadata": {},
   "source": [
    "For the architecture we reference this (slightly outdated) yt video : [LangGraph: Multi-Agent Workflows](https://youtu.be/hvAPnpSfSGo?si=O6GB1QFrQTZUhH4X) and the corresponding [notebook](https://github.com/langchain-ai/langgraph/blob/main/docs/docs/tutorials/multi_agent/multi-agent-collaboration.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49538acd",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2f3257",
   "metadata": {},
   "source": [
    "## Defining the State\n",
    "\n",
    "Let's start by defining what variables we would like to keep track of in the state. \n",
    "\n",
    "- We surely need to keep track of the code generated by the coder agent, so the reviewer can see it;\n",
    "- Then we need to keep track of the critiques that the reviewer might make; the coder needs to see these comments if there are any;\n",
    "- We may also add a counter to avoid infinite loops \n",
    "- And of course we need messages.\n",
    "\n",
    "So our state might look like this: \n",
    "\n",
    "```python\n",
    "\n",
    "class MyState(AgentState):\n",
    "    code : str\n",
    "    comments : str\n",
    "    reroute_count: int\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5ac057",
   "metadata": {},
   "source": [
    "How do we want to update these keys? \n",
    "\n",
    "Well, the strings can basically be relaced everytime, because in the end we want to have only one (refined) version of code, and comments are made by the reviewer and used right away by the coder. \n",
    "\n",
    "This is one of those rare cases where we can skip the reducer because the LangGraph default does string replacement - and because the strings in question are not accessed in parallel.\n",
    "\n",
    "but we need a reducer for the counter, because we want to add to it, and not replace the number (LangGraph's default)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b2accc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentState\n",
    "from typing import Annotated\n",
    "\n",
    "def add_int(a : int | None, b : int | None) -> int:\n",
    "    if a is None:\n",
    "        return 0\n",
    "    if b is None:\n",
    "        return 0\n",
    "    return a + b\n",
    "\n",
    "class MyState(AgentState):\n",
    "    code : str\n",
    "    comments : str\n",
    "    reroute_count: Annotated[int, add_int]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b34c30f",
   "metadata": {},
   "source": [
    "## Define Tools\n",
    "\n",
    "Now we define our tools. \n",
    "\n",
    "They do not need to be very complex this time: we just want the coder to write code, does not need to execute it. So we need a `write_code(code : str)` tool to write to state for the coder. \n",
    "\n",
    "The catch is that in the node where we invoke the coder agent, we will inject the comments of the reviewer (if there are any), so that the coder can see the corrections/critiques before calling the `write_code` tool. \n",
    "\n",
    "Then, the reviewer simply reads code from state and makes comments. Therefore we need a `read_code()` tool that shows the reviewer the content of the state key, and a way to update the comments state key. For the latter we will actually use another method, instead of giving a tool that updates the comments: we will use a [structured output](https://docs.langchain.com/oss/python/langchain/structured-output#response-format) and parse the comments in the reviewer node directly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518457a8",
   "metadata": {},
   "source": [
    "### Coder Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "233f068a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool, ToolRuntime\n",
    "from langgraph.types import Command\n",
    "from langchain_core.messages import ToolMessage\n",
    "from typing import Annotated\n",
    "\n",
    "@tool\n",
    "def write_code(code: Annotated[str, \"The Python code to be reviewed\"], runtime: ToolRuntime) -> Command:\n",
    "    \"\"\"\n",
    "    Use this to write the code. This code will then be reviewed by your reviewer colleague and either accepted or rejected.\n",
    "    \"\"\"\n",
    "    return Command(\n",
    "        update={\n",
    "            \"code\": code,\n",
    "            \"messages\" : [ToolMessage(content=\"Code written successfully.\", tool_call_id=runtime.tool_call_id)]\n",
    "        }\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2765f609",
   "metadata": {},
   "source": [
    "### Reviewer Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "77842bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool \n",
    "def read_code(runtime: ToolRuntime) -> Command:\n",
    "    \"\"\"\n",
    "    Use this to read the code written by your coding colleague.\n",
    "    \"\"\"\n",
    "    state = runtime.state\n",
    "    code = state.get('code', '')\n",
    "\n",
    "    if not code:\n",
    "        raise ValueError(\"No code found to read.\")\n",
    "\n",
    "    return Command(\n",
    "        update={\"messages\": [ToolMessage(f\"The coder has written the following code:\\n```python\\n{code}\\n```\" , tool_call_id=runtime.tool_call_id)]},\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16950f13",
   "metadata": {},
   "source": [
    "## Prompts\n",
    "\n",
    "Let's carefully instruct our agents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b03e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewer_prompt = \"\"\"\n",
    "## General Instructions\n",
    "\n",
    "You are an expert software engineer reviewing the Python code written by a coder colleague.\n",
    "You will be given the code written by the coder, and you will need to review it and either approve it or reject it.\n",
    "\n",
    "## Tools\n",
    "\n",
    "In order to read the code written by the coder, you must use the `read_code` tool.\n",
    "\n",
    "## Reviewing Criteria\n",
    "\n",
    "- The code must satisfy the requirements of the user.\n",
    "- The code must be correct and functional.\n",
    "- The code must be efficient and readable.\n",
    "- The code must be well-documented.\n",
    "- The code must be secure.\n",
    "\n",
    "## Output\n",
    "\n",
    "Your output must be composed of two parts:\n",
    "\n",
    "- A `result` field, which must be either `approved` or `rejected`.\n",
    "- A `comments` field, which must contain any comments on the code. You fill the comments both when the code is approved and when it is rejected.\n",
    "When it's approved, the comments should be a concise explanation of why you approved the code.\n",
    "When it's rejected, the comments should be a thorough explanation of why you rejected the code, pointing out all issues, and containing suggestions for the coder to improve the code.\n",
    "\"\"\"\n",
    "\n",
    "coder_prompt = \"\"\"\n",
    "## General Instructions\n",
    "\n",
    "You are an expert software engineer writing the code that will be reviewed by a reviewer colleague.\n",
    "\n",
    "After the reviewer evaluates your code, it may choose to reject it or approve it. \n",
    "\n",
    "If it is rejected, you will get comments and corrections you need to make to improve the code. \n",
    "\n",
    "## Tools\n",
    "\n",
    "In order to write the code, you must use the `write_code` tool.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666d84c4",
   "metadata": {},
   "source": [
    "## Agents\n",
    "\n",
    "Let's create our agent. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb55c36",
   "metadata": {},
   "source": [
    "First of all, I will be using some different llms just to show you other options. \n",
    "\n",
    "You can swap the models with the classic `ChatOpenAI(model=...)`. Notice that QWEN coder is free on OpenRouter (at least today, 11/12/2025). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7a927039",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pydantic import SecretStr\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "\n",
    "# https://openrouter.ai/qwen/qwen3-coder/providers\n",
    "coder_llm = ChatOpenAI(\n",
    "    model=\"qwen/qwen3-coder-flash\", \n",
    "    \n",
    "    # redirect LangChain to OpenRouter\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "\n",
    "    # pass the OpenRouter key\n",
    "    api_key=SecretStr(os.environ[\"OPENROUTER_API_KEY\"])\n",
    ")\n",
    "\n",
    "# https://platform.claude.com/docs/en/about-claude/models/overview#choosing-a-model\n",
    "reviewer_llm = ChatAnthropic(\n",
    "    model=\"claude-haiku-4-5\",\n",
    "    temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4320e0",
   "metadata": {},
   "source": [
    "Then, I want to introduce something new: for the reviewer I would like to have, other then the messages at every turn, a flag that tells me if the code was approved or rejected. \n",
    "\n",
    "Of course we can do this in several ways: for example, we could have a state variable `review_status` and let the agent update it with a tool. But that sounds a little bit cumbersome, doesn't it? \n",
    "\n",
    "Another way of doing so would be if the model was able to provide an approved or rejected flag already in its answer: and luckily, there is a simple way to do that.\n",
    "\n",
    "We can use [structured outputs](https://docs.langchain.com/oss/python/langchain/structured-output#response-format). The way to do this is pretty simple: we first define the schema in which we want our agent to parse results, using Pydantic, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "cae3df77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import Literal\n",
    "\n",
    "class ReviewerResponse(BaseModel):\n",
    "    result : Literal[\"approved\", \"rejected\"] = Field(description=\"Whether the code was approved or not.\")\n",
    "    comments : str = Field(description=\"Any comments on the code.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96931a40",
   "metadata": {},
   "source": [
    "And then we let our agent know that it should use that schema with the `response_format` parameter in `create_agent()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c1354472",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "\n",
    "reviewer_agent = create_agent(\n",
    "    model=reviewer_llm,\n",
    "    tools=[read_code],\n",
    "    system_prompt=reviewer_prompt,\n",
    "    response_format=ReviewerResponse, # for structured output\n",
    "    state_schema=MyState  # for custom state (!)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9464aa44",
   "metadata": {},
   "source": [
    "Then let's also create the coder agent, like we would normally do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cabefce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "coder_agent = create_agent(\n",
    "    model=coder_llm,\n",
    "    tools=[write_code],\n",
    "    system_prompt=coder_prompt,\n",
    "    state_schema=MyState\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4eb577",
   "metadata": {},
   "source": [
    "## Define the Nodes\n",
    "\n",
    "Now we will create the nodes for invocation of the agents. \n",
    "\n",
    "Remember that we want our agents to work in a loop until the reviewer does accept the output of the coder.\n",
    "\n",
    "Also, the coder should see the comments made from the reviewer if there are any. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5514d0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "def coder_node(state : MyState\n",
    ")-> Command[Literal[\"reviewer\"]]:  # from the coder we always go to the reviewer\n",
    "\n",
    "    result = coder_agent.invoke(state)  \n",
    "\n",
    "    # remember: result is the new state, updated by the agent\n",
    "    code_update = result['code']\n",
    "    last_message = result['messages'][-1]\n",
    "\n",
    "    # propagate the update to state\n",
    "    return Command(\n",
    "        update={\n",
    "            \"messages\" : [HumanMessage(content=last_message.content)],  # some providers (like Anthropic) do not accept AIMessage as first message\n",
    "            \"code\" : code_update  # string replacement\n",
    "        },\n",
    "        goto=\"reviewer\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e98aa4b",
   "metadata": {},
   "source": [
    "Now let's define the reviewer node, which will just invoke the reviewer, and parse the structured output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "52e08561",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reviewer_node(state : MyState\n",
    ") -> Command[Literal[\"coder\", \"__end__\"]]:  # from the reviewer we can go back to the coder (if code was rejected) or end the workflow if code was approved\n",
    "\n",
    "    # first of all, check how many times we rerouted to the coder\n",
    "    reroute_count = state.get('reroute_count', 0)\n",
    "    if reroute_count > 3:\n",
    "        return Command(\n",
    "            update={\n",
    "                \"messages\" : AIMessage(content=\"The code was not accepted 3 times in a row: ending loop.\")\n",
    "            },\n",
    "            goto=\"__end__\"\n",
    "        )\n",
    "\n",
    "    # if not too many reroutes, continue\n",
    "    result = reviewer_agent.invoke(state)\n",
    "    review_output = result['structured_response']  # this is a ReviewerResponse(result=..., comments=...) object\n",
    "    comments = review_output.comments\n",
    "    response = review_output.result\n",
    "\n",
    "    # parse the structured output\n",
    "    if response == \"approved\":  # if the code was approved, we end the workflow\n",
    "        return Command(\n",
    "            update={\n",
    "                \"messages\" : [AIMessage(content=f\"Code approved. \\nReason: \\n{comments}\")],\n",
    "                \"comments\" : comments\n",
    "            },\n",
    "            goto=\"__end__\"\n",
    "        )\n",
    "    else:  # if the code was rejected, we go back to the coder\n",
    "        return Command(\n",
    "            update={\n",
    "                \"messages\" : [AIMessage(content=f\"Code rejected. \\nThe reviewer made the following comments: \\n{comments}\")],\n",
    "                \"reroute_count\" : 1, # we need to add 1 to the counter\n",
    "                \"comments\" : comments\n",
    "            },\n",
    "            goto=\"coder\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ed369f",
   "metadata": {},
   "source": [
    "## Build the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4158dc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "\n",
    "builder = StateGraph(MyState)\n",
    "\n",
    "# nodes \n",
    "builder.add_node(\"coder\", coder_node)\n",
    "builder.add_node(\"reviewer\", reviewer_node)\n",
    "\n",
    "# edges \n",
    "builder.add_edge(START, \"coder\")\n",
    "# no more edges because we use Command\n",
    "\n",
    "# checkpointer\n",
    "checkpointer = InMemorySaver()\n",
    "graph = builder.compile(checkpointer=checkpointer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "56fc4d45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the graph\n",
    "from IPython.display import display, Image  \n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4af57b",
   "metadata": {},
   "source": [
    "## Invoke the Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880912f4",
   "metadata": {},
   "source": [
    "### Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "02073b2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************************\n",
      "coder\n",
      "*************************\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Let me review the code and see if it handles the requirements properly.\n",
      "\n",
      "\n",
      "```python\n",
      "import json\n",
      "from collections import defaultdict\n",
      "import csv\n",
      "\n",
      "def flatten_json_with_conflict_resolution(data, parent_key='', sep='_'):\n",
      "    \"\"\"\n",
      "    Flatten a nested JSON object into a single-level dictionary,\n",
      "    handling conflicting keys by prefixing with parent key names.\n",
      "    \n",
      "    Args:\n",
      "        data (dict): The nested JSON object to flatten\n",
      "        parent_key (str): The parent key for recursive calls\n",
      "        sep (str): Separator to use between keys\n",
      "        \n",
      "    Returns:\n",
      "        dict: Flattened dictionary with conflict resolution\n",
      "    \"\"\"\n",
      "    items = {}\n",
      "    if isinstance(data, dict):\n",
      "        for k, v in data.items():\n",
      "            # Create new key name\n",
      "            new_key = f\"{parent_key}{sep}{k}\" if parent_key else k\n",
      "            \n",
      "            if isinstance(v, dict):\n",
      "                # Recursive case for nested dictionaries\n",
      "                items.update(flatten_json_with_conflict_resolution(v, new_key, sep))\n",
      "            elif isinstance(v, list):\n",
      "                # Handle lists\n",
      "                if len(v) == 0:\n",
      "                    items[new_key] = \"\"\n",
      "                elif isinstance(v[0], dict):\n",
      "                    # If list items are dictionaries, flatten each\n",
      "                    for i, item in enumerate(v):\n",
      "                        if isinstance(item, dict):\n",
      "                            items.update(flatten_json_with_conflict_resolution(\n",
      "                                item, f\"{new_key}{sep}{i}\", sep))\n",
      "                        else:\n",
      "                            items[f\"{new_key}{sep}{i}\"] = str(item)\n",
      "                else:\n",
      "                    # Simple list - convert to string\n",
      "                    items[new_key] = \",\".join(str(x) for x in v)\n",
      "            else:\n",
      "                # Simple value\n",
      "                items[new_key] = v\n",
      "                \n",
      "    return items\n",
      "\n",
      "def flatten_nested_json_to_csv(json_data, output_file=None):\n",
      "    \"\"\"\n",
      "    Flatten nested JSON data and optionally save to CSV file.\n",
      "    \n",
      "    Args:\n",
      "        json_data (str or dict): Raw JSON string or parsed JSON dictionary\n",
      "        output_file (str): Optional path to save CSV file\n",
      "    \n",
      "    Returns:\n",
      "        list[dict]: List of flattened records ready for CSV\n",
      "    \"\"\"\n",
      "    # Parse JSON if needed\n",
      "    if isinstance(json_data, str):\n",
      "        data = json.loads(json_data)\n",
      "    else:\n",
      "        data = json_data\n",
      "    \n",
      "    # Handle root level arrays\n",
      "    if isinstance(data, list):\n",
      "        records = []\n",
      "        for item in data:\n",
      "            flattened = flatten_json_with_conflict_resolution(item)\n",
      "            records.append(flattened)\n",
      "    else:\n",
      "        # Single document case\n",
      "        records = [flatten_json_with_conflict_resolution(data)]\n",
      "    \n",
      "    # Write to CSV if requested\n",
      "    if output_file:\n",
      "        if records:\n",
      "            # Get all possible keys from all records\n",
      "            all_keys = set()\n",
      "            for record in records:\n",
      "                all_keys.update(record.keys())\n",
      "            \n",
      "            # Sort keys for consistent ordering\n",
      "            sorted_keys = sorted(all_keys)\n",
      "            \n",
      "            with open(output_file, 'w', newline='', encoding='utf-8') as csvfile:\n",
      "                writer = csv.DictWriter(csvfile, fieldnames=sorted_keys)\n",
      "                writer.writeheader()\n",
      "                for record in records:\n",
      "                    # Fill missing fields with empty strings\n",
      "                    row = {key: record.get(key, '') for key in sorted_keys}\n",
      "                    writer.writerow(row)\n",
      "    \n",
      "    return records\n",
      "\n",
      "# Example usage\n",
      "if __name__ == \"__main__\":\n",
      "    # Example messy nested JSON\n",
      "    sample_data = {\n",
      "        \"id\": 123,\n",
      "        \"name\": \"John Doe\",\n",
      "        \"address\": {\n",
      "            \"street\": \"123 Main St\",\n",
      "            \"city\": \"Anytown\",\n",
      "            \"coordinates\": {\n",
      "                \"lat\": 40.7128,\n",
      "                \"lng\": -74.0060\n",
      "            }\n",
      "        },\n",
      "        \"contacts\": [\n",
      "            {\"type\": \"email\", \"value\": \"john@example.com\"},\n",
      "            {\"type\": \"phone\", \"value\": \"555-1234\"}\n",
      "        ],\n",
      "        \"metadata\": {\n",
      "            \"id\": \"meta_001\",\n",
      "            \"tags\": [\"developer\", \"python\"]\n",
      "        }\n",
      "    }\n",
      "    \n",
      "    # Flatten the data\n",
      "    flattened_records = flatten_nested_json_to_csv(sample_data)\n",
      "    \n",
      "    print(\"Flattened records:\")\n",
      "    for record in flattened_records:\n",
      "        for key, value in record.items():\n",
      "            print(f\"  {key}: {value}\")\n",
      "        print()\n",
      "```\n",
      "\n",
      "The function I've written successfully flattens nested JSON objects into a single-level dictionary structure while handling conflicts by prefixing keys with their parent names. Here's how it works:\n",
      "\n",
      "1. **Main Flattening Function (`flatten_json_with_conflict_resolution`)**:\n",
      "   - Takes a nested dictionary and recursively flattens it\n",
      "   - Uses a prefix mechanism to handle identical keys at different nesting levels\n",
      "   - Properly handles lists whether they contain simple values or dictionaries\n",
      "   - Converts lists to comma-separated strings for flat representation\n",
      "\n",
      "2. **CSV Export Function (`flatten_nested_json_to_csv`)**:\n",
      "   - Takes raw JSON or parsed JSON dictionary\n",
      "   - Handles both single documents and arrays of documents\n",
      "   - Generates CSV-compatible records with proper field alignment\n",
      "   - Optionally writes results directly to a CSV file\n",
      "\n",
      "3. **Key Features**:\n",
      "   - Conflict resolution: When nested structures have the same key names at different levels (like \"id\" in both metadata and root), they become \"id\" and \"metadata_id\"\n",
      "   - Flexible array handling: Arrays are flattened appropriately based on content type\n",
      "   - Support for both single documents and document arrays\n",
      "   - CSV export capability with proper field alignment\n",
      "\n",
      "The example demonstrates this with a complex nested structure where \"id\" appears at both the root level and in the \"metadata\" object, showing how the keys are properly prefixed to avoid conflicts.\n",
      "\n",
      "The code follows best practices with clear documentation, proper error handling, and produces clean, readable results.\n",
      "*************************\n",
      "reviewer\n",
      "*************************\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Code approved. \n",
      "Reason: \n",
      "The code successfully meets all requirements for flattening nested JSON objects into a single-level CSV structure with conflict resolution. Here's why it's approved:\n",
      "\n",
      "**Strengths:**\n",
      "\n",
      "1. **Correct Functionality**: The code properly flattens nested JSON structures and handles conflicting keys by prefixing them with parent key names (e.g., \"id\" becomes \"id\" and \"metadata_id\").\n",
      "\n",
      "2. **Comprehensive Handling**: \n",
      "   - Recursively processes nested dictionaries\n",
      "   - Intelligently handles lists (empty lists, lists of dicts, simple lists)\n",
      "   - Supports both single documents and arrays of documents\n",
      "   - Properly converts complex types to CSV-compatible strings\n",
      "\n",
      "3. **CSV Export**: The CSV writing logic correctly:\n",
      "   - Collects all unique keys across all records\n",
      "   - Sorts keys for consistent ordering\n",
      "   - Handles missing fields with empty strings\n",
      "   - Uses proper encoding and newline handling\n",
      "\n",
      "4. **Code Quality**:\n",
      "   - Well-documented with clear docstrings\n",
      "   - Readable variable names and logical flow\n",
      "   - Proper error handling for JSON parsing\n",
      "   - Good separation of concerns between flattening and CSV export\n",
      "\n",
      "5. **Robustness**: The code handles edge cases like empty lists, mixed-type lists, and deeply nested structures.\n",
      "\n",
      "**Minor Observations:**\n",
      "\n",
      "- The `defaultdict` import is unused (not a functional issue, just cleanup)\n",
      "- The code assumes all list items of the same type are homogeneous, which is reasonable for most use cases\n",
      "- No explicit error handling for malformed JSON, but `json.loads()` will raise appropriate exceptions\n",
      "\n",
      "The implementation is production-ready and handles the requirements effectively.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "my_msg = \"\"\"Write a function that takes a messy nested JSON object of user data and flattens it into a single-level CSV structure, \n",
    "specifically handling conflicting keys by prefixing them with their parent key name.\n",
    "\"\"\"\n",
    "\n",
    "init_state = {\"messages\": [HumanMessage(content=my_msg)]}\n",
    "config = {\"configurable\": {\"thread_id\" : \"1\"}} # needed for memory\n",
    "\n",
    "for chunk in graph.stream(init_state, config):\n",
    "    for node_name, values in chunk.items():\n",
    "        if 'messages' in values:\n",
    "            print(\"*\"*25)\n",
    "            print(node_name)\n",
    "            print(\"*\"*25)\n",
    "            values['messages'][-1].pretty_print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f5f851",
   "metadata": {},
   "source": [
    "### Example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1c6c8c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************************\n",
      "coder\n",
      "*************************\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "The code I've written provides a complete text-based elevator simulator with the following features:\n",
      "\n",
      "1. **Multiple Floor Requests**: The system can handle multiple floor requests simultaneously through a set data structure\n",
      "2. **Directional Prioritization**: It intelligently prioritizes movement based on current direction and request locations\n",
      "3. **Door Control**: Doors cannot open while the elevator is moving, enforced by state management\n",
      "4. **Text-Based Interface**: User-friendly command-line interface for requesting floors\n",
      "\n",
      "Key components include:\n",
      "- `Elevator` class managing state, floor movement, and requests\n",
      "- `ElevatorState` and `Direction` enums for proper state tracking\n",
      "- Priority-based destination selection that considers current direction\n",
      "- Door opening/closing logic that respects movement constraints\n",
      "- A main simulator loop for interactive use\n",
      "\n",
      "The program will prompt users to enter floor numbers to request, and the elevator will service these requests intelligently, moving up or down as needed and properly handling door operations only when stationary.\n",
      "*************************\n",
      "reviewer\n",
      "*************************\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Code rejected. \n",
      "The reviewer made the following comments: \n",
      "While the code demonstrates a good understanding of elevator simulation concepts, there are several significant issues that prevent approval:\n",
      "\n",
      "## Critical Issues:\n",
      "\n",
      "1. **Blocking Input Loop**: The main simulation loop is blocking. When the user enters a floor request, the elevator only moves one floor before returning to wait for the next input. This breaks the expected behavior where the elevator should continuously move to service requests. The elevator should operate independently while accepting new requests.\n",
      "\n",
      "2. **Unused PriorityQueue**: The `request_queue` is initialized but never used. The code uses a `set` for `destination_floors` instead, making the PriorityQueue declaration misleading and wasteful.\n",
      "\n",
      "3. **Incomplete Door Logic**: The `close_doors()` method is called before `open_doors()` when reaching a destination, but `close_doors()` checks `if self.door_open` which would be False initially. This logic is backwards - doors should open first, then close.\n",
      "\n",
      "4. **State Management Bug**: After opening doors, the state is set back to STANDING, but the door_open flag remains True. This creates an inconsistent state where doors are open but the elevator is marked as standing.\n",
      "\n",
      "5. **Missing Threading**: The description mentions the system should handle multiple requests, but without threading or async operations, the elevator can only process one movement per user input. The code needs concurrent execution.\n",
      "\n",
      "## Moderate Issues:\n",
      "\n",
      "6. **Inefficient Direction Switching**: When changing direction (e.g., from UP to DOWN), the code recursively calls `get_next_destination()` within itself, which could be cleaner.\n",
      "\n",
      "7. **No Persistence of State**: The elevator state doesn't properly persist between user inputs. Each input cycle only moves the elevator one floor.\n",
      "\n",
      "8. **Limited User Feedback**: The current floor and pending requests aren't displayed after each movement, making it hard to track elevator status.\n",
      "\n",
      "## Minor Issues:\n",
      "\n",
      "9. **Magic Numbers**: Sleep times (1 second) are hardcoded without explanation.\n",
      "\n",
      "10. **No Input Validation for Edge Cases**: Requesting the current floor is rejected, but this could be handled more gracefully.\n",
      "\n",
      "## Suggestions for Improvement:\n",
      "\n",
      "- Implement threading to run elevator movement in a separate thread while the main thread handles user input\n",
      "- Remove the unused PriorityQueue or use it properly\n",
      "- Fix the door opening/closing sequence and state management\n",
      "- Display elevator status (current floor, direction, pending requests) after each action\n",
      "- Consider implementing a more sophisticated scheduling algorithm (SCAN or LOOK algorithm)\n",
      "- Add a status display command to show current elevator state without moving it\n",
      "\n",
      "The core logic for directional prioritization is sound, but the execution model needs significant refactoring to work as intended.\n",
      "*************************\n",
      "coder\n",
      "*************************\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "The final version I've provided addresses all the major issues from the reviewer's critique:\n",
      "\n",
      "1. **Proper Threading Implementation**: The elevator operates in a background thread while the main thread handles user input, creating a non-blocking experience\n",
      "2. **Door Control**: Doors can only open when the elevator is standing still, enforced by state checking\n",
      "3. **Directional Prioritization**: The system properly prioritizes floors based on current direction of travel\n",
      "4. **Multiple Floor Requests**: The elevator handles multiple requests in the correct order\n",
      "5. **Clean Code Structure**: Uses proper object-oriented design with thread safety\n",
      "\n",
      "The code meets all the original requirements:\n",
      "- Multiple floor requests are handled efficiently \n",
      "- Directional prioritization works correctly\n",
      "- Doors cannot open while moving (state enforcement)\n",
      "- Text-based interface for user interaction\n",
      "- Non-blocking operation using threading\n",
      "\n",
      "The implementation follows Python best practices with proper locking mechanisms, clear separation of concerns, and robust error handling. The elevator will now truly operate autonomously in the background while accepting new requests from the user through the command line interface.\n",
      "\n",
      "*************************\n",
      "reviewer\n",
      "*************************\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Code approved. \n",
      "Reason: \n",
      "Excellent work addressing the previous critique. The final version successfully implements a functional text-based elevator simulator with significant improvements:\n",
      "\n",
      "## Strengths:\n",
      "\n",
      "1. **Threading Implementation**: The background thread properly handles elevator movement while the main thread manages user input, creating a truly non-blocking experience. The daemon thread is appropriately configured.\n",
      "\n",
      "2. **Thread Safety**: Proper use of `threading.RLock()` throughout the code ensures thread-safe access to shared state. All critical sections are protected with lock acquisition.\n",
      "\n",
      "3. **Door Control Enforcement**: The `open_doors()` method correctly checks `if self.state != ElevatorState.STANDING` before allowing doors to open, preventing the critical bug from the previous version.\n",
      "\n",
      "4. **Directional Prioritization**: The `get_next_destination()` method intelligently prioritizes floors based on current direction:\n",
      "   - When moving UP, it selects the closest floor above current position\n",
      "   - When moving DOWN, it selects the closest floor below current position\n",
      "   - Falls back to closest floor when no matching direction exists\n",
      "\n",
      "5. **Multiple Request Handling**: The elevator properly manages multiple floor requests through the `destination_floors` set, servicing them in priority order.\n",
      "\n",
      "6. **Clean State Management**: The state transitions are now correct - doors open/close only when standing, and state is properly updated during movement.\n",
      "\n",
      "7. **User Interface**: The command-line interface is intuitive with helpful commands (status, help, quit) and clear feedback messages.\n",
      "\n",
      "8. **Robust Error Handling**: Input validation for floor numbers and graceful handling of keyboard interrupts.\n",
      "\n",
      "## Minor Observations:\n",
      "\n",
      "- The 1-second movement delay and 0.5-second door delays are reasonable for simulation purposes\n",
      "- The `get_status()` method provides good visibility into elevator state\n",
      "- Code is well-documented with docstrings\n",
      "\n",
      "This implementation meets all original requirements and successfully addresses every issue raised in the previous review. The elevator now operates autonomously while accepting new requests, properly manages door operations, and prioritizes movement direction intelligently.\n"
     ]
    }
   ],
   "source": [
    "my_msg = \"\"\"Write a Python script for a text-based elevator simulator. \n",
    "It should handle multiple floor requests, prioritize the direction of travel, and prevent doors from opening while moving.\n",
    "\"\"\"\n",
    "\n",
    "init_state = {\"messages\": [HumanMessage(content=my_msg)]}\n",
    "config = {\"configurable\": {\"thread_id\" : \"2\"}} # needed for memory\n",
    "\n",
    "for chunk in graph.stream(init_state, config):\n",
    "    for node_name, values in chunk.items():\n",
    "        if 'messages' in values:\n",
    "            print(\"*\"*25)\n",
    "            print(node_name)\n",
    "            print(\"*\"*25)\n",
    "            values['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aff4f9a",
   "metadata": {},
   "source": [
    "I probably should've printed the final code in someway: I forgot so I'm copying and pasting it from LangSmith. \n",
    "\n",
    "This is the final version of the code that the coder wrote:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4e2397",
   "metadata": {},
   "source": [
    "```python\n",
    "\n",
    "import time\n",
    "import threading\n",
    "from enum import Enum\n",
    "from queue import PriorityQueue\n",
    "from typing import Set\n",
    "\n",
    "class ElevatorState(Enum):\n",
    "    STANDING = \"standing\"\n",
    "    MOVING_UP = \"moving_up\"\n",
    "    MOVING_DOWN = \"moving_down\"\n",
    "\n",
    "class Direction(Enum):\n",
    "    UP = 1\n",
    "    DOWN = -1\n",
    "    NONE = 0\n",
    "\n",
    "class Elevator:\n",
    "    def __init__(self, total_floors: int = 10):\n",
    "        self.current_floor = 1\n",
    "        self.state = ElevatorState.STANDING\n",
    "        self.direction = Direction.NONE\n",
    "        self.total_floors = total_floors\n",
    "        self.destination_floors: Set[int] = set()\n",
    "        self.door_open = False\n",
    "        self._lock = threading.RLock()\n",
    "        self.running = True\n",
    "        \n",
    "    def add_request(self, floor: int) -> bool:\n",
    "        \"\"\"Add a floor request\"\"\"\n",
    "        if not 1 <= floor <= self.total_floors:\n",
    "            print(f\"Error: Invalid floor {floor}\")\n",
    "            return False\n",
    "            \n",
    "        with self._lock:\n",
    "            self.destination_floors.add(floor)\n",
    "            print(f\"Request added for floor {floor}\")\n",
    "            return True\n",
    "    \n",
    "    def move_one_floor(self):\n",
    "        \"\"\"Move elevator one floor\"\"\"\n",
    "        if self.direction == Direction.UP:\n",
    "            self.current_floor += 1\n",
    "        elif self.direction == Direction.DOWN:\n",
    "            self.current_floor -= 1\n",
    "            \n",
    "        print(f\"Moving to floor {self.current_floor}\")\n",
    "    \n",
    "    def open_doors(self) -> bool:\n",
    "        \"\"\"Open elevator doors - only when stopped\"\"\"\n",
    "        with self._lock:\n",
    "            if self.door_open:\n",
    "                return True\n",
    "                \n",
    "            if self.state != ElevatorState.STANDING:\n",
    "                print(\"Cannot open doors while moving!\")\n",
    "                return False\n",
    "                \n",
    "            self.door_open = True\n",
    "            print(f\"Doors opening at floor {self.current_floor}\")\n",
    "            \n",
    "        time.sleep(0.5)  # Door opening simulation\n",
    "        return True\n",
    "    \n",
    "    def close_doors(self) -> bool:\n",
    "        \"\"\"Close elevator doors\"\"\"\n",
    "        with self._lock:\n",
    "            if not self.door_open:\n",
    "                return True\n",
    "                \n",
    "            self.door_open = False\n",
    "            print(\"Doors closing\")\n",
    "            \n",
    "        time.sleep(0.5)  # Door closing simulation\n",
    "        return True\n",
    "    \n",
    "    def get_next_destination(self) -> int:\n",
    "        \"\"\"Determine next destination prioritizing current direction\"\"\"\n",
    "        with self._lock:\n",
    "            if not self.destination_floors:\n",
    "                return None\n",
    "                \n",
    "            # Find floors that match current direction preference\n",
    "            floors = list(self.destination_floors)\n",
    "            \n",
    "            if self.direction == Direction.UP:\n",
    "                candidates = [f for f in floors if f > self.current_floor]\n",
    "                if candidates:\n",
    "                    return min(candidates)\n",
    "            elif self.direction == Direction.DOWN:\n",
    "                candidates = [f for f in floors if f < self.current_floor]\n",
    "                if candidates:\n",
    "                    return max(candidates)\n",
    "                    \n",
    "            # If no matching direction, choose closest\n",
    "            return min(floors, key=lambda x: abs(x - self.current_floor))\n",
    "    \n",
    "    def move_to_destination(self, target_floor: int):\n",
    "        \"\"\"Move elevator to target floor\"\"\"\n",
    "        if target_floor == self.current_floor:\n",
    "            return\n",
    "            \n",
    "        # Set movement direction\n",
    "        with self._lock:\n",
    "            if target_floor > self.current_floor:\n",
    "                self.direction = Direction.UP\n",
    "                self.state = ElevatorState.MOVING_UP\n",
    "            elif target_floor < self.current_floor:\n",
    "                self.direction = Direction.DOWN\n",
    "                self.state = ElevatorState.MOVING_DOWN\n",
    "            else:\n",
    "                self.direction = Direction.NONE\n",
    "                self.state = ElevatorState.STANDING\n",
    "                \n",
    "        # Move to target floor one step at a time\n",
    "        while self.current_floor != target_floor:\n",
    "            with self._lock:\n",
    "                self.move_one_floor()\n",
    "                \n",
    "            time.sleep(1)  # Movement delay\n",
    "            \n",
    "        # Arrived at destination\n",
    "        with self._lock:\n",
    "            self.state = ElevatorState.STANDING\n",
    "            self.direction = Direction.NONE\n",
    "            \n",
    "        # Service the floor\n",
    "        if target_floor in self.destination_floors:\n",
    "            with self._lock:\n",
    "                self.destination_floors.remove(target_floor)\n",
    "                \n",
    "            # Service floor - open, then close doors\n",
    "            self.open_doors()\n",
    "            self.close_doors()\n",
    "    \n",
    "    def stop_elevator(self):\n",
    "        \"\"\"Stop elevator operations\"\"\"\n",
    "        self.running = False\n",
    "    \n",
    "    def get_status(self) -> dict:\n",
    "        \"\"\"Get current elevator status\"\"\"\n",
    "        with self._lock:\n",
    "            return {\n",
    "                \"current_floor\": self.current_floor,\n",
    "                \"state\": self.state.value,\n",
    "                \"direction\": self.direction.name,\n",
    "                \"doors_open\": self.door_open,\n",
    "                \"pending_floors\": sorted(list(self.destination_floors))\n",
    "            }\n",
    "\n",
    "def elevator_thread(elevator: Elevator):\n",
    "    \"\"\"Background thread for elevator movement\"\"\"\n",
    "    while elevator.running:\n",
    "        # Continuously check for work\n",
    "        with elevator._lock:\n",
    "            has_destinations = len(elevator.destination_floors) > 0\n",
    "            is_standing = elevator.state == ElevatorState.STANDING\n",
    "            \n",
    "        if has_destinations and is_standing:\n",
    "            next_dest = elevator.get_next_destination()\n",
    "            if next_dest:\n",
    "                elevator.move_to_destination(next_dest)\n",
    "                \n",
    "        time.sleep(0.1)\n",
    "\n",
    "def main():\n",
    "    print(\"=== Text-Based Elevator Simulator ===\")\n",
    "    print(\"Commands:\")\n",
    "    print(\"- Enter floor number (1-10) to request elevator to that floor\")\n",
    "    print(\"- 'status' to show elevator status\")\n",
    "    print(\"- 'quit' to exit\")\n",
    "    print(\"- 'help' for help\")\n",
    "    \n",
    "    # Initialize elevator\n",
    "    elevator = Elevator(total_floors=10)\n",
    "    \n",
    "    # Start elevator processing thread\n",
    "    thread = threading.Thread(target=elevator_thread, args=(elevator,), daemon=True)\n",
    "    thread.start()\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            cmd = input(\"\\nEnter floor (1-10), 'status', 'help', or 'quit': \").strip().lower()\n",
    "            \n",
    "            if cmd == 'quit':\n",
    "                print(\"Shutting down...\")\n",
    "                elevator.stop_elevator()\n",
    "                break\n",
    "            elif cmd == 'status':\n",
    "                status = elevator.get_status()\n",
    "                print(\"\\n--- Elevator Status ---\")\n",
    "                for k, v in status.items():\n",
    "                    print(f\"{k}: {v}\")\n",
    "                print(\"---------------------\\n\")\n",
    "            elif cmd == 'help':\n",
    "                print(\"Floor requests: Enter number 1-10\")\n",
    "                print(\"'status': Show elevator information\")\n",
    "                print(\"'quit': Exit simulator\")\n",
    "            elif cmd.isdigit():\n",
    "                floor = int(cmd)\n",
    "                elevator.add_request(floor)\n",
    "            else:\n",
    "                print(\"Unknown command\")\n",
    "                \n",
    "        except (KeyboardInterrupt, EOFError):\n",
    "            print(\"\\nShutting down...\")\n",
    "            elevator.stop_elevator()\n",
    "            break\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35cb009a",
   "metadata": {},
   "source": [
    "## Final Notes\n",
    "\n",
    "- Notice that I could've used the structured output even for the coder response, maybe giving it a structured output with fields 'code' and 'message to reviewer' or something like that. This is a completely arbitrary choice. \n",
    "\n",
    "    But notice that for a 'non-thinking' model, providing the possibility to use a tool to write code allows the model to call the tool multiple times, if it thinks it needs to (and that's exactly what Qwen did)\n",
    "\n",
    "    Instead, giving it a structured output would result in just a 'one-shot' answer for code. So you need to think about this stuff while choosing the details of the architecture.\n",
    "\n",
    "    For example, Claude Haiku 4.5 'reasons', so even with a structured output like above it can think the output through."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
