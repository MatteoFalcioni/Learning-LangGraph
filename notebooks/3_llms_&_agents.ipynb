{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3882f99b",
   "metadata": {},
   "source": [
    "## Simple Graph w/ LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1954a131",
   "metadata": {},
   "source": [
    "Now we want to actually leverage an llm in our graph. How can we do that? \n",
    "\n",
    "The steps are actually very similar, with just some small tweaks:\n",
    "- in the node we will now call an llm (we'll see how)\n",
    "- we will be using the `MessagesState` class provided by LangGraph as state (so we skip state definition)\n",
    "\n",
    "Let's expand on both concepts:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a902d103",
   "metadata": {},
   "source": [
    "### State\n",
    "\n",
    "We said that we can create LangGraph states by using `TypedDict`, and that still holds on when we use llm's. But, LangGraph has actually built pre-defined state for us to use in this sort of applications: so why re-invent the wheel?\n",
    "\n",
    "More specifically, we have the [`MessagesState`](https://docs.langchain.com/oss/python/langgraph/graph-api#messagesstate) class: \"Since having a list of messages in your state is so common, there exists a prebuilt state called MessagesState which makes it easy to use messages.\" \n",
    "\n",
    "At its core, `MessagesState` is just a `TypedDict` with a list of strings - the messages.\n",
    "\n",
    "Since we will be using that, we can skip state creation and afterwards we will just instantiate `StateGraph(MessagesState)` when building the graph. \n",
    "\n",
    ">If we want a more complex state other than just messages, we can expand the pre-built class with other fields. We will do that later on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94f7399",
   "metadata": {},
   "source": [
    "### Nodes\n",
    "\n",
    "Now our nodes: actually we just need a node that calls our llm with the given message. \n",
    "\n",
    "How can we build that? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa69d199",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()  # load api keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34eeff9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import MessagesState\n",
    "from langchain_core.messages import AIMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model='gpt-4o')\n",
    "\n",
    "def call_llm(state: MessagesState) -> MessagesState:\n",
    "    \"\"\"A simple node that calls an llm with the messages in state.\"\"\"\n",
    "\n",
    "    result = llm.invoke(state['messages'])  # invoke the llm on our state - the result is an AIMessage\n",
    "\n",
    "    return {\"messages\" : [result]}  # wrap it in a list for updates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3545f4a",
   "metadata": {},
   "source": [
    "This simple implementation contains precious information. \n",
    "\n",
    "We can see how we are invoking our llm on the state's `messages`, and using the result to update our graph state.\n",
    "\n",
    "**(!) Returning a Dictionary of Updates:** this is a crucial concept in LangGraph, and sometimes counterintuitive. **Nodes do not return a new state**, they must **only return state updates**. This is how LangGraph processes nodes outputs.\n",
    "\n",
    "In this case, we are updating our `'messages'` list in state with the last message produced by our AI model. Notice how we are wrapping it in a list: this is because the `MessagesState`'s *reducer* (see later on) is made to work with lists."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac77a99",
   "metadata": {},
   "source": [
    "### Edges (building the graph)\n",
    "\n",
    "We have all the core pieces, we just need to link them together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe1875ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from IPython.display import Image, display\n",
    "\n",
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(\"llm\", call_llm)\n",
    "builder.add_edge(START, \"llm\")\n",
    "builder.add_edge(\"llm\", END)\n",
    "\n",
    "graph = builder.compile()\n",
    "\n",
    "# View\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95766289",
   "metadata": {},
   "source": [
    "### Invoke the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94fe0a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "init_message= HumanMessage(content=\"Hello, who are you?\")\n",
    "\n",
    "response = graph.invoke({\"messages\" : [init_message]})   # notice we need to wrap it in a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86ec82f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hello, who are you?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello! I'm an AI language model developed by OpenAI. I'm here to assist you with a variety of questions and tasks, like providing information, answering queries, and giving recommendations. How can I help you today?\n"
     ]
    }
   ],
   "source": [
    "for message in response['messages']:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3654830",
   "metadata": {},
   "source": [
    "## Agent Graph\n",
    "\n",
    "Now we will implement a graph that invokes an llm with tools: an agentic system."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede1f59f",
   "metadata": {},
   "source": [
    "The structure of our graph will be the following:\n",
    "\n",
    "<img src=\"./images/better_agent_w_tools.png\" alt=\"Descrizione immagine\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80fa98d9",
   "metadata": {},
   "source": [
    "### State\n",
    "\n",
    "Again, we will actually skip state creation (don't worry: it will come back in the next notebook), since we will be using the `create_agent()` built-in function from `langchain.agents`. This automatically defaults to the `AgentState` class (which is an upgrade of `MessagesState`).\n",
    "\n",
    "More on this class later on - right now let's just focus on how we can create an agent: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22a8c02",
   "metadata": {},
   "source": [
    "### `create_agent()`\n",
    "\n",
    "We already said that we just want *a simple graph that invokes an agent, and loops with some tools*. So, the immediate thing that comes to mind would be to create an 'agent' node, a 'tools' node, and connect them with edges. \n",
    "\n",
    "We could do that, but *LangGraph kindly does it for us already* :) . All of this is implemented in one of LangGraph core functions, the [**`create_agent()` function**](https://reference.langchain.com/python/langchain/agents/?h=agent#langchain.agents.create_agent)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2941427b",
   "metadata": {},
   "source": [
    ">For more info on how you would build this from basic langgraph principles, see [this link](https://docs.langchain.com/oss/python/langgraph/workflows-agents#agents). `create_agent()` basically implements:\n",
    ">-  an '`llm_call`' node where we invoke the agent, \n",
    ">- a '`tool`' node where we check what tools the llm called - and then execute the calls\n",
    ">- and a '`should_continue`' conditional edge that checks wether the llm made tool calls or not. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febe0293",
   "metadata": {},
   "source": [
    "Let's create our agent!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02ef650c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=\"\"\"\n",
    "You are a helpful assistant that can use tools to answer questions.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "585d525c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o\")  # choose a model\n",
    "\n",
    "agent_v0 = create_agent(  # version 0\n",
    "    model=model,\n",
    "    tools=[],  # empty list for now\n",
    "    system_prompt=prompt,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c0c017",
   "metadata": {},
   "source": [
    "The `tools` field is now an empty list, so the agent defaults to a simple llm without tools.\n",
    "\n",
    "Let's give it some tools."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3d1912",
   "metadata": {},
   "source": [
    "### Defining Tools\n",
    "\n",
    "Defining tools is quite simple: we just need to write a function and decorate it with the `@tool` decorator. \n",
    "\n",
    "Let's create an example tool that just elevates a number to the power of another number. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3484a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "\n",
    "@tool\n",
    "def power(base: int, exponent: int) -> int:\n",
    "    \"\"\"\n",
    "    Use this to elevate a number to the power of another number.\n",
    "    Args:\n",
    "        base: int - the base\n",
    "        exponent: int - the exponent\n",
    "    \"\"\"\n",
    "    return base**exponent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f73764",
   "metadata": {},
   "source": [
    "Inside this simple tool we have some precious information for working with LangGraph. Let's dissect what we wrote: \n",
    "\n",
    "1. **Parameters:** the parameters of the tool are obviously our base and our exponent. The key concept is that these parameters **will be filled by the agent**. As a matter of fact, the agent has the ability to call any python function we decorate with `@tool`. \n",
    "\n",
    "    It calls these tools as we would: after we define the above function, if **we** wanted to use it in code we would do something like: \n",
    "    ```python\n",
    "    result = power(base=3, exponent=4)  # compute 3**4\n",
    "    ```\n",
    "    And this is exactly what the agent will do: it will call the function, filling out the parameters.\n",
    "\n",
    "2. **Documentation:** notice we gave our simple tool some docstring to describe what it does and how to use it. This was not made for good practices, **it is actually required in tools definitions**. These docstrings are *read by the agent* and specify to it how it should use the given functions, and what parameters it should pass as input. If we do not write any docstring, the code would error!\n",
    "\n",
    "3. On the same page, **Type Hints** are very useful for agents, and we should always specify those as well.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2409a68",
   "metadata": {},
   "source": [
    "#### Give Tools to the Agent\n",
    "\n",
    "Now that we created our tool, we can actually create the new version of our agent with such tools: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68816127",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_v1 = create_agent(  # version 1\n",
    "    model=model,\n",
    "    tools=[power],  # add the tool here\n",
    "    system_prompt=prompt,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de36ae72",
   "metadata": {},
   "source": [
    "### Invocation\n",
    "\n",
    "We can actually directly invoke an agent created with `create_agent()` without building a graph with nodes and edges. \n",
    "\n",
    "This is because the function creates a compiled graph already. So for example we can already do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "939f7d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = agent_v1.invoke({\"messages\" : [HumanMessage(content=\"What is 3 to the power of 4?\")]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d1805d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is 3 to the power of 4?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  power (call_PIWX4VQnzq1ZS1L0rLb3w46j)\n",
      " Call ID: call_PIWX4VQnzq1ZS1L0rLb3w46j\n",
      "  Args:\n",
      "    base: 3\n",
      "    exponent: 4\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: power\n",
      "\n",
      "81\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "3 to the power of 4 is 81.\n"
     ]
    }
   ],
   "source": [
    "for message in result['messages']:\n",
    "    message.pretty_print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
