{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "735d65db",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/MatteoFalcioni/Learning-LangGraph/blob/main/notebooks/9.5_exercises.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e3f9cc",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb1cb51",
   "metadata": {},
   "source": [
    "#### Install requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3edea4eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='pypi.org', port=443): Read timed out. (read timeout=15)\")': /simple/langgraph/\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q -U -r https://raw.githubusercontent.com/MatteoFalcioni/Learning-LangGraph/main/requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5214fe8a",
   "metadata": {},
   "source": [
    "#### local (notebooks or files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd05dca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()  # load api keys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea827fdc",
   "metadata": {},
   "source": [
    "#### Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1bd7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import userdata\n",
    "import os\n",
    "\n",
    "REQUIRED_KEYS = [\n",
    "    'OPENAI_API_KEY',\n",
    "    'LANGSMITH_TRACING',\n",
    "    'LANGSMITH_ENDPOINT',\n",
    "    'LANGSMITH_API_KEY',\n",
    "    'LANGSMITH_PROJECT'\n",
    "]\n",
    "\n",
    "def _set_colab_keys(key : str):\n",
    "    # Retrieve the secret value using its key/name\n",
    "    secret_value = userdata.get(key)\n",
    "    # set it as a standard OS environment variable\n",
    "    os.environ[key] = secret_value\n",
    "\n",
    "for key in REQUIRED_KEYS:\n",
    "    _set_colab_keys(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c70014b",
   "metadata": {},
   "source": [
    "# Exercises (Lessons 8 & 9)\n",
    "\n",
    "Recapping at this stage becomes ever increasingly difficult: we are building complex applications, and seeing details of LangGraph (like structured outputs) as we go on. \n",
    "\n",
    "Therefore, for the sake of my mental sanity, notebooks numbered with .5 will from now on be more oriented towards exercises (and solutions, if requested in class). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6153350a",
   "metadata": {},
   "source": [
    "## Lecture 8\n",
    "\n",
    "\n",
    "### Ex. 8.1 \n",
    "\n",
    "The exercises for this lesson is very democratic: \n",
    "\n",
    "choose one of the 3 human in the loop pattern we've gone through and implement one. It can really be anything, enjoy yourself!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60ae53c",
   "metadata": {},
   "source": [
    "## Lecture 9 \n",
    "\n",
    "You will find the exercises being more and more difficult as we go on - obviously, otherwise we wouldn't learnanything D:\n",
    "\n",
    "This exercise is the natural coninuation of the graph of lecture 9: we built an agent that writes code, another agent that reviewes it... but what about execution? \n",
    "\n",
    "### Ex. 9.1\n",
    "\n",
    "Extend the graph of lecture 9 with code execution capabilities. You can choose wether to:\n",
    "\n",
    "**a)** Add another agent after the reviewer that actually executes the code. This agent must be a 'tester', in the sense that it tests that the execution does not error, and if it does it routes back to the code writer with critiques and fixes. \n",
    "\n",
    "**b)** Or, you can choose to give a code execution tool to the reviewer, so that it can actually test the code after approving it, and do both jobs. \n",
    "\n",
    "My personal choice would probably be option **b)**, just because splitting the same \"reviewing\" role between two agents does not seem very efficient. But maybe it works better in the end, who knows! I leave the choice to you."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
